# Object-Segmentation-on-ARMBENCH

Robotic systems have revolutionized the warehouse industry by automating tasks such as unpacking, loading, sorting and packing. With robotic manufacturing equipment, warehouses can ensure that
these tasks are performed safely and efficiently, increasing efficiency and productivity. Enabling automation in robotic manipulators requires the ability to perceive and understand their environment,
as well as the products and services at hand. Perception systems allow robots to receive sensory feedback from sensors including cameras, depth sensors and tactile sensors. Sensory systems for
attachable and connectable robotic manipulators include object recognition, object tracking, grasp planning, error detection etc.

In this, I will be focusing on the aspect of object detection and instance segmentation in perception systems for manipulators. While supervised learning models have made object detection,
classification, and recognition feasible in computer vision, applying these methods to perception systems in modern warehouses with robotic manipulators presents unique challenges. Manipulators
must navigate diverse resources, disorganized archives, and ever-changing inventories, making it difficult to identify resources, material properties, and position accuracy during manipulation.
Existing datasets for robotic manipulation typically have limited feature sets or rely on synthetic images from 3D models, which do not capture all feature types, and interactions encountered in
real-world situations. Amazon Robotics has unveiled ARMBench, the first extensive benchmark dataset developed for robotic pick-and-place tasks. These data systems include a variety of warehouse
products and systems, aimed at solving the challenges encountered in storage systemsin warehouses.
